"""Module pour recommandations IA locales avec GPT4All."""
import os
from pathlib import Path
from gpt4all import GPT4All

# R√©cup√©ration du chemin du mod√®le depuis le .env ou dossier local par d√©faut
MODEL_PATH = os.getenv("GPT4ALL_MODEL_PATH", Path(__file__).parent / "models" / "ggml-gpt4all-j-v1.3-groovy.bin")

# T√©l√©chargement automatique si le fichier mod√®le est manquant
if not Path(MODEL_PATH).exists():
    import requests
    MODEL_PATH.parent.mkdir(parents=True, exist_ok=True)
    url = "https://gpt4all.io/models/ggml-gpt4all-j-v1.3-groovy.bin"  # lien officiel
    print(f"üì• T√©l√©chargement du mod√®le GPT4All depuis {url} ...")
    r = requests.get(url, stream=True)
    with open(MODEL_PATH, "wb") as f:
        for chunk in r.iter_content(chunk_size=8192):
            f.write(chunk)
    print("‚úÖ Mod√®le GPT4All t√©l√©charg√©.")

# Chargement du mod√®le GPT4All
llm = GPT4All(str(MODEL_PATH), verbose=True)

def generate_recommendations(prompt: str, n: int = 5) -> str:
    """
    G√©n√®re des recommandations locales √† partir du prompt.
    """
    response = llm.generate(prompt, max_tokens=512)
    return response
